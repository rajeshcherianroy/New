{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSmuc4sBWb8MxfVkHI/SGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshcherianroy/New/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "zDasWaYTFTke",
        "outputId": "ac84101c-8e45-4640-9285-8b14fe3d5a48"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import struct\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from matplotlib.patches import Rectangle\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "\n",
        "\n",
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major, = struct.unpack('i', w_f.read(4))\n",
        "            minor, = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            if (major * 10 + minor) >= 2 and \\\n",
        "                    major < 1000 and \\\n",
        "                    minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            binary = w_f.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary,\n",
        "                                         dtype='float32')\n",
        "\n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset - size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in tqdm.tqdm(range(106)):\n",
        "            try:\n",
        "                conv_layer = model.get_layer(f'conv_{i}')\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer(f'bnorm_{i}')\n",
        "                    size = np.prod(norm_layer.\n",
        "                                   get_weights()[0].shape)\n",
        "                    bias = self.read_bytes(size)\n",
        "                    scale = self.read_bytes(size)\n",
        "                    mean = self.read_bytes(size)\n",
        "                    var = self.read_bytes(size)\n",
        "\n",
        "                    norm_layer.set_weights([scale, bias,\n",
        "                                            mean, var])\n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias = self.read_bytes(np.prod(\n",
        "                        conv_layer.get_weights()[1].shape))\n",
        "\n",
        "                    kernel = self.read_bytes(np.prod(\n",
        "                        conv_layer.get_weights()[0].shape))\n",
        "\n",
        "                    kernel = kernel.reshape(list(reversed(\n",
        "                        conv_layer.get_weights()[0].shape)))\n",
        "\n",
        "                    kernel = kernel.transpose([2, 3, 1, 0])\n",
        "\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(\n",
        "                        conv_layer.get_weights()[0].shape))\n",
        "\n",
        "                    kernel = kernel.reshape(list(reversed(\n",
        "                        conv_layer.get_weights()[0].shape)))\n",
        "\n",
        "                    kernel = kernel.transpose([2, 3, 1, 0])\n",
        "\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "    def reset(self):\n",
        "        self.offset = 0\n",
        "\n",
        "\n",
        "class BoundBox(object):\n",
        "    def __init__(self, x_min, y_min, x_max, y_max,\n",
        "                 objness=None,\n",
        "                 classes=None):\n",
        "        self.xmin = x_min\n",
        "        self.ymin = y_min\n",
        "        self.xmax = x_max\n",
        "        self.ymax = y_max\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score\n",
        "\n",
        "\n",
        "class YOLO(object):\n",
        "    def __init__(self, weights_path,\n",
        "                 anchors_path='resources/anchors.json',\n",
        "                 labels_path='resources/coco_labels.txt',\n",
        "                 class_threshold=0.65):\n",
        "        self.weights_path = weights_path\n",
        "        self.model = self._load_yolo()\n",
        "\n",
        "        self.labels = []\n",
        "        with open(labels_path, 'r') as f:\n",
        "            for l in f:\n",
        "                self.labels.append(l.strip())\n",
        "\n",
        "        with open(anchors_path, 'r') as f:\n",
        "            self.anchors = json.load(f)\n",
        "\n",
        "        self.class_threshold = class_threshold\n",
        "\n",
        "    def _conv_block(self, input, convolutions, skip=True):\n",
        "        x = input\n",
        "        count = 0\n",
        "        for conv in convolutions:\n",
        "            if count == (len(convolutions) - 2) and skip:\n",
        "                skip_connection = x\n",
        "\n",
        "            count += 1\n",
        "\n",
        "            if conv['stride'] > 1:\n",
        "                x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
        "\n",
        "            x = Conv2D(conv['filter'],\n",
        "                       conv['kernel'],\n",
        "                       strides=conv['stride'],\n",
        "                       padding=('valid' if conv['stride'] > 1\n",
        "                                else 'same'),\n",
        "                       name=f'conv_{conv[\"layer_idx\"]}',\n",
        "                       use_bias=(False if conv['bnorm']\n",
        "                                 else True))(x)\n",
        "\n",
        "            if conv['bnorm']:\n",
        "                name = f'bnorm_{conv[\"layer_idx\"]}'\n",
        "                x = BatchNormalization(epsilon=1e-3,\n",
        "                                       name=name)(x)\n",
        "            if conv['leaky']:\n",
        "                name = f'leaky_{conv[\"layer_idx\"]}'\n",
        "                x = LeakyReLU(alpha=0.1, name=name)(x)\n",
        "\n",
        "        return Add()([skip_connection, x]) if skip else x\n",
        "\n",
        "    def _make_yolov3_architecture(self):\n",
        "        input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "        # Layer  0 => 4\n",
        "        x = self._conv_block(input_image, [\n",
        "            {'filter': 32, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True,\n",
        "             'leaky': True, 'layer_idx': 0},\n",
        "            {'filter': 64, 'kernel': 3, 'stride': 2,\n",
        "             'bnorm': True,\n",
        "             'leaky': True, 'layer_idx': 1},\n",
        "            {'filter': 32, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True,\n",
        "             'leaky': True, 'layer_idx': 2},\n",
        "            {'filter': 64, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True,\n",
        "             'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "        # Layer  5 => 8\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 128, 'kernel': 3, 'stride': 2,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "            {'filter': 64, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "            {'filter': 128, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "        # Layer  9 => 11\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 64, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "            {'filter': 128, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "        # Layer 12 => 15\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 256, 'kernel': 3, 'stride': 2,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "            {'filter': 128, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "            {'filter': 256, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "        # Layer 16 => 36\n",
        "        for i in range(7):\n",
        "            x = self._conv_block(x, [\n",
        "                {'filter': 128, 'kernel': 1, 'stride': 1,\n",
        "                 'bnorm': True, 'leaky': True,\n",
        "                 'layer_idx': 16 + i * 3},\n",
        "                {'filter': 256, 'kernel': 3, 'stride': 1,\n",
        "                 'bnorm': True, 'leaky': True,\n",
        "                 'layer_idx': 17 + i * 3}])\n",
        "        skip_36 = x\n",
        "\n",
        "        # Layer 37 => 40\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 512, 'kernel': 3, 'stride': 2,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "            {'filter': 256, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "            {'filter': 512, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "        # Layer 41 => 61\n",
        "        for i in range(7):\n",
        "            x = self._conv_block(x, [\n",
        "                {'filter': 256, 'kernel': 1, 'stride': 1,\n",
        "                 'bnorm': True, 'leaky': True,\n",
        "                 'layer_idx': 41 + i * 3},\n",
        "                {'filter': 512, 'kernel': 3, 'stride': 1,\n",
        "                 'bnorm': True, 'leaky': True,\n",
        "                 'layer_idx': 42 + i * 3}])\n",
        "        skip_61 = x\n",
        "\n",
        "        # Layer 62 => 65\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 1024, 'kernel': 3, 'stride': 2,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "            {'filter': 512, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "            {'filter': 1024, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "        # Layer 66 => 74\n",
        "        for i in range(3):\n",
        "            x = self._conv_block(x, [\n",
        "                {'filter': 512, 'kernel': 1, 'stride': 1,\n",
        "                 'bnorm': True, 'leaky': True,\n",
        "                 'layer_idx': 66 + i * 3},\n",
        "                {'filter': 1024, 'kernel': 3, 'stride': 1,\n",
        "                 'bnorm': True, 'leaky': True,\n",
        "                 'layer_idx': 67 + i * 3}])\n",
        "\n",
        "        # Layer 75 => 79\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 512, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "            {'filter': 1024, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "            {'filter': 512, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "            {'filter': 1024, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "            {'filter': 512, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 79}],\n",
        "                             skip=False)\n",
        "\n",
        "        # Layer 80 => 82\n",
        "        yolo_82 = self._conv_block(x, [\n",
        "            {'filter': 1024, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 80},\n",
        "            {'filter': 255, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': False, 'leaky': False,\n",
        "             'layer_idx': 81}], skip=False)\n",
        "\n",
        "        # Layer 83 => 86\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 256, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 84}],\n",
        "                             skip=False)\n",
        "        x = UpSampling2D(2)(x)\n",
        "        x = Concatenate()([x, skip_61])\n",
        "\n",
        "        # Layer 87 => 91\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 256, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "            {'filter': 512, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "            {'filter': 256, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "            {'filter': 512, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "            {'filter': 256, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 91}],\n",
        "                             skip=False)\n",
        "        # Layer 92 => 94\n",
        "        yolo_94 = self._conv_block(x, [\n",
        "            {'filter': 512, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 92},\n",
        "            {'filter': 255, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': False, 'leaky': False,\n",
        "             'layer_idx': 93}], skip=False)\n",
        "\n",
        "        # Layer 95 => 98\n",
        "        x = self._conv_block(x, [\n",
        "            {'filter': 128, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 96}],\n",
        "                             skip=False)\n",
        "        x = UpSampling2D(2)(x)\n",
        "        x = Concatenate()([x, skip_36])\n",
        "\n",
        "        # Layer 99 => 106\n",
        "        yolo_106 = self._conv_block(x, [\n",
        "            {'filter': 128, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 99},\n",
        "            {'filter': 256, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 100},\n",
        "            {'filter': 128, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 101},\n",
        "            {'filter': 256, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 102},\n",
        "            {'filter': 128, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 103},\n",
        "            {'filter': 256, 'kernel': 3, 'stride': 1,\n",
        "             'bnorm': True, 'leaky': True, 'layer_idx': 104},\n",
        "            {'filter': 255, 'kernel': 1, 'stride': 1,\n",
        "             'bnorm': False, 'leaky': False,\n",
        "             'layer_idx': 105}], skip=False)\n",
        "\n",
        "        return Model(inputs=input_image,\n",
        "                     outputs=[yolo_82, yolo_94, yolo_106])\n",
        "\n",
        "    def _load_yolo(self):\n",
        "        model = self._make_yolov3_architecture()\n",
        "        weight_reader = WeightReader(self.weights_path)\n",
        "        weight_reader.load_weights(model)\n",
        "        model.save('model.h5')\n",
        "\n",
        "        model = load_model('model.h5')\n",
        "\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def _sigmoid(x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "    def _decode_net_output(self, network_output,\n",
        "                           anchors,\n",
        "                           obj_thresh,\n",
        "                           network_height,\n",
        "                           network_width):\n",
        "        grid_height, grid_width = network_output.shape[:2]\n",
        "        nb_box = 3\n",
        "        network_output = network_output.reshape(\n",
        "            (grid_height, grid_width, nb_box, -1))\n",
        "\n",
        "        boxes = []\n",
        "        network_output[..., :2] = \\\n",
        "            self._sigmoid(network_output[..., :2])\n",
        "        network_output[..., 4:] = \\\n",
        "            self._sigmoid(network_output[..., 4:])\n",
        "        network_output[..., 5:] = \\\n",
        "            (network_output[..., 4][..., np.newaxis] *\n",
        "             network_output[..., 5:])\n",
        "        network_output[..., 5:] *= \\\n",
        "            network_output[..., 5:] > obj_thresh\n",
        "\n",
        "        for i in range(grid_height * grid_width):\n",
        "            r = i / grid_width\n",
        "            c = i % grid_width\n",
        "\n",
        "            for b in range(nb_box):\n",
        "                objectness = \\\n",
        "                    network_output[int(r)][int(c)][b][4]\n",
        "\n",
        "                if objectness.all() <= obj_thresh:\n",
        "                    continue\n",
        "\n",
        "                x, y, w, h = \\\n",
        "                    network_output[int(r)][int(c)][b][:4]\n",
        "                x = (c + x) / grid_width\n",
        "                y = (r + y) / grid_height\n",
        "                w = (anchors[2 * b] * np.exp(w) /\n",
        "                     network_width)\n",
        "                h = (anchors[2 * b + 1] * np.exp(h) /\n",
        "                     network_height)\n",
        "\n",
        "                classes = network_output[int(r)][c][b][5:]\n",
        "                box = BoundBox(x_min=x - w / 2,\n",
        "                               y_min=y - h / 2,\n",
        "                               x_max=x + w / 2,\n",
        "                               y_max=y + h / 2,\n",
        "                               objness=objectness,\n",
        "                               classes=classes)\n",
        "                boxes.append(box)\n",
        "\n",
        "        return boxes\n",
        "\n",
        "    @staticmethod\n",
        "    def _correct_yolo_boxes(boxes,\n",
        "                            image_height,\n",
        "                            image_width,\n",
        "                            network_height,\n",
        "                            network_width):\n",
        "        new_w, new_h = network_width, network_height\n",
        "\n",
        "        for i in range(len(boxes)):\n",
        "            x_offset = (network_width - new_w) / 2.0\n",
        "            x_offset /= network_width\n",
        "            x_scale = float(new_w) / network_width\n",
        "\n",
        "            y_offset = (network_height - new_h) / 2.0\n",
        "            y_offset /= network_height\n",
        "            y_scale = float(new_h) / network_height\n",
        "\n",
        "            boxes[i].xmin = int((boxes[i].xmin - x_offset) /\n",
        "                                x_scale * image_width)\n",
        "            boxes[i].xmax = int((boxes[i].xmax - x_offset) /\n",
        "                                x_scale * image_width)\n",
        "            boxes[i].ymin = int((boxes[i].ymin - y_offset) /\n",
        "                                y_scale * image_height)\n",
        "            boxes[i].ymax = int((boxes[i].ymax - y_offset) /\n",
        "                                y_scale * image_height)\n",
        "\n",
        "    @staticmethod\n",
        "    def _interval_overlap(interval_a, interval_b):\n",
        "        x1, x2 = interval_a\n",
        "        x3, x4 = interval_b\n",
        "\n",
        "        if x3 < x1:\n",
        "            if x4 < x1:\n",
        "                return 0\n",
        "            else:\n",
        "                return min(x2, x4) - x1\n",
        "        else:\n",
        "            if x2 < x3:\n",
        "                return 0\n",
        "            else:\n",
        "                return min(x2, x4) - x3\n",
        "\n",
        "    def _bbox_iou(self, box1, box2):\n",
        "        intersect_w = self._interval_overlap(\n",
        "            [box1.xmin, box1.xmax],\n",
        "            [box2.xmin, box2.xmax])\n",
        "        intersect_h = self._interval_overlap(\n",
        "            [box1.ymin, box1.ymax],\n",
        "            [box2.ymin, box2.ymax])\n",
        "\n",
        "        intersect = intersect_w * intersect_h\n",
        "\n",
        "        w1, h1 = box1.xmax - box1.xmin, box1.ymax - box1.ymin\n",
        "        w2, h2 = box2.xmax - box2.xmin, box2.ymax - box2.ymin\n",
        "\n",
        "        union = w1 * h1 + w2 * h2 - intersect\n",
        "        return float(intersect) / union\n",
        "\n",
        "    def _non_max_suppression(self, boxes, nms_thresh):\n",
        "        if len(boxes) > 0:\n",
        "            nb_class = len(boxes[0].classes)\n",
        "        else:\n",
        "            return\n",
        "\n",
        "        for c in range(nb_class):\n",
        "            sorted_indices = np.argsort(\n",
        "                [-box.classes[c] for box in boxes])\n",
        "\n",
        "            for i in range(len(sorted_indices)):\n",
        "                index_i = sorted_indices[i]\n",
        "\n",
        "                if boxes[index_i].classes[c] == 0:\n",
        "                    continue\n",
        "\n",
        "                for j in range(i + 1, len(sorted_indices)):\n",
        "                    index_j = sorted_indices[j]\n",
        "                    iou = self._bbox_iou(boxes[index_i],\n",
        "                                         boxes[index_j])\n",
        "                    if iou >= nms_thresh:\n",
        "                        boxes[index_j].classes[c] = 0\n",
        "\n",
        "    def _get_boxes(self, boxes):\n",
        "        v_boxes, v_labels, v_scores = [], [], []\n",
        "\n",
        "        for box in boxes:\n",
        "            print(len(self.labels))\n",
        "            for i in range(len(self.labels)):\n",
        "                if box.classes[i] > self.class_threshold:\n",
        "                    v_boxes.append(box)\n",
        "                    v_labels.append(self.labels[i])\n",
        "                    v_scores.append(box.classes[i] * 100)\n",
        "\n",
        "        return v_boxes, v_labels, v_scores\n",
        "\n",
        "    @staticmethod\n",
        "    def _draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "        data = plt.imread(filename)\n",
        "        plt.imshow(data)\n",
        "\n",
        "        ax = plt.gca()\n",
        "\n",
        "        for i in range(len(v_boxes)):\n",
        "            box = v_boxes[i]\n",
        "\n",
        "            y1, x1, y2, x2 = \\\n",
        "                box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\n",
        "            width = x2 - x1\n",
        "            height = y2 - y1\n",
        "\n",
        "            rectangle = Rectangle((x1, y1), width, height,\n",
        "                                  fill=False, color='white')\n",
        "\n",
        "            ax.add_patch(rectangle)\n",
        "            label = f'{v_labels[i]} ({v_scores[i]:.3f})'\n",
        "            plt.text(x1, y1, label, color='yellow')\n",
        "        plt.show()\n",
        "\n",
        "    def detect(self, image, width, height):\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        preds = self.model.predict(image)\n",
        "\n",
        "        boxes = []\n",
        "\n",
        "        for i in range(len(preds)):\n",
        "            boxes.extend(\n",
        "                self._decode_net_output(preds[i][0],\n",
        "                                        self.anchors[i],\n",
        "                                        self.class_threshold,\n",
        "                                        416,\n",
        "                                        416))\n",
        "\n",
        "        self._correct_yolo_boxes(boxes, height, width, 416,\n",
        "                                 416)\n",
        "        self._non_max_suppression(boxes, .5)\n",
        "\n",
        "        valid_boxes, valid_labels, valid_scores = \\\n",
        "            self._get_boxes(boxes)\n",
        "\n",
        "        for i in range(len(valid_boxes)):\n",
        "            print(valid_labels[i], valid_scores[i])\n",
        "\n",
        "        self._draw_boxes(image_path,\n",
        "                         valid_boxes,\n",
        "                         valid_labels,\n",
        "                         valid_scores)\n",
        "\n",
        "\n",
        "\n",
        "model = YOLO(weights_path='./resources/yolov3.weights')\n",
        "\n",
        "for image_path in glob.glob('./test_images/*.jpg'):\n",
        "    image = load_img(image_path, target_size=(416, 416))\n",
        "    image = img_to_array(image)\n",
        "    image = image.astype('float32') / 255.0\n",
        "\n",
        "    original_image = load_img(image_path)\n",
        "    width, height = original_image.size\n",
        "\n",
        "    model.detect(image, width, height)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 106/106 [00:00<00:00, 146.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe468420dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-dafe32f145ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-dafe32f145ff>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, image, width, height)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_max_suppression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mvalid_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_scores\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-dafe32f145ff>\u001b[0m in \u001b[0;36m_get_boxes\u001b[0;34m(self, boxes)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                     \u001b[0mv_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mv_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 80 is out of bounds for axis 0 with size 80"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR_C4hjbdRyU",
        "outputId": "b22e3a16-3c2e-48cf-868e-6b321ce2b4f7"
      },
      "source": [
        "for image_path in glob.glob('./test_images/*.jpg'):\n",
        "    image = load_img(image_path, target_size=(416, 416))\n",
        "    image = img_to_array(image)\n",
        "    image = image.astype('float32') / 255.0\n",
        "    print(image.shape)\n",
        "    original_image = load_img(image_path)\n",
        "    width, height = original_image.size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(416, 416, 3)\n",
            "(416, 416, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}